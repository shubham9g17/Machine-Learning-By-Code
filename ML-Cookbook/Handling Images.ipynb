{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Loading Images\n",
    "### Problem\n",
    "You want to load an image for preprocessing.\n",
    "### Solution\n",
    "Use OpenCV’s imread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "plt.imshow(image, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image data\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dimensions\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image in color\n",
    "image_bgr = cv2.imread(\"download.jfif\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "# Show image\n",
    "plt.imshow(image_rgb), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Saving Images\n",
    "### Problem\n",
    "You want to save an image for preprocessing.\n",
    "### Solution\n",
    "Use OpenCV’s imwrite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Save image\n",
    "cv2.imwrite(\"download-copy.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Resizing Images\n",
    "### Problem\n",
    "You want to resize an image for further preprocessing.\n",
    "### Solution\n",
    "Use resize to change the size of an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize image to 50 pixels by 50 pixels\n",
    "image_50x50 = cv2.resize(image, (50, 50))\n",
    "# View image\n",
    "plt.imshow(image_50x50, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Cropping Images\n",
    "### Problem\n",
    "You want to remove the outer portion of the image to change its dimensions.\n",
    "### Solution\n",
    "The image is encoded as a two-dimensional NumPy array, so we can crop the image\n",
    "easily by slicing the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image in grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Select first half of the columns and all rows\n",
    "image_cropped = image[:,:128]\n",
    "# Show image\n",
    "plt.imshow(image_cropped, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Blurring Images\n",
    "### Problem\n",
    "You want to smooth out an image.\n",
    "### Solution\n",
    "To blur an image, each pixel is transformed to be the average value of its neighbors.\n",
    "This neighbor and the operation performed are mathematically represented as a kernel (don’t worry if you don’t know what a kernel is). The size of this kernel determines the amount of blurring, with larger kernels producing smoother images. Here\n",
    "we blur an image by averaging the values of a 5 × 5 kernel around each pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Blur image\n",
    "image_blurry = cv2.blur(image, (5,5))\n",
    "# Show image\n",
    "plt.imshow(image_blurry, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Sharpening Images\n",
    "### Problem\n",
    "You want to sharpen an image.\n",
    "### Solution\n",
    "Create a kernel that highlights the target pixel. Then apply it to the image using fil\n",
    "ter2D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Create kernel\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]])\n",
    "# Sharpen image\n",
    "image_sharp = cv2.filter2D(image, -1, kernel)\n",
    "# Show image\n",
    "plt.imshow(image_sharp, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Enhancing Contrast\n",
    "### Problem\n",
    "We want to increase the contrast between pixels in an image.\n",
    "### Solution\n",
    "Histogram equalization is a tool for image processing that can make objects and\n",
    "shapes stand out. When we have a grayscale image, we can apply OpenCV’s equali\n",
    "zeHist directly on the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Enhance image\n",
    "image_enhanced = cv2.equalizeHist(image)\n",
    "# Show image\n",
    "plt.imshow(image_enhanced, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Isolating Colors\n",
    "### Problem\n",
    "You want to isolate a color in an image.\n",
    "### Solution\n",
    "Define a range of colors and then apply a mask to the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image\n",
    "image_bgr = cv2.imread('download.jfif')\n",
    "# Convert BGR to HSV\n",
    "image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "# Define range of blue values in HSV\n",
    "lower_blue = np.array([50,100,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "# Create mask\n",
    "mask = cv2.inRange(image_hsv, lower_blue, upper_blue)\n",
    "# Mask image\n",
    "image_bgr_masked = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)\n",
    "# Convert BGR to RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB)\n",
    "# Show image\n",
    "plt.imshow(image_rgb), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image\n",
    "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 Binarizing Images\n",
    "### Problem\n",
    "Given an image, you want to output a simplified version.\n",
    "### Solution\n",
    "Thresholding is the process of setting pixels with intensity greater than some value to\n",
    "be white and less than the value to be black. A more advanced technique is adaptive\n",
    "thresholding, where the threshold value for a pixel is determined by the pixel intensi‐\n",
    "ties of its neighbors. This can be helpful when lighting conditions change over differ‐\n",
    "ent regions in an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image_grey = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Apply adaptive thresholding\n",
    "max_output_value = 255\n",
    "neighborhood_size = 99\n",
    "subtract_from_mean = 10\n",
    "image_binarized = cv2.adaptiveThreshold(image_grey,\n",
    "                                        max_output_value,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY,\n",
    "                                        neighborhood_size,\n",
    "                                        subtract_from_mean)\n",
    "# Show image\n",
    "plt.imshow(image_binarized, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "image_mean_threshold = cv2.adaptiveThreshold(image_grey,\n",
    "                                             max_output_value,\n",
    "                                             cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                             cv2.THRESH_BINARY,\n",
    "                                             neighborhood_size,\n",
    "                                             subtract_from_mean)\n",
    "# Show image\n",
    "plt.imshow(image_mean_threshold, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Removing Backgrounds\n",
    "### Problem\n",
    "You want to isolate the foreground of an image.\n",
    "### Solution\n",
    "Mark a rectangle around the desired foreground, then run the GrabCut algorithm:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and convert to RGB\n",
    "image_bgr = cv2.imread('download.jfif')\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "# Rectangle values: start x, start y, width, height\n",
    "rectangle = (0, 56, 256, 150)\n",
    "# Create initial mask\n",
    "mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
    "# Create temporary arrays used by grabCut\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "# Run grabCut\n",
    "cv2.grabCut(image_rgb, # Our image\n",
    "            mask, # The Mask\n",
    "            rectangle, # Our rectangle\n",
    "            bgdModel, # Temporary array for background\n",
    "            fgdModel, # Temporary array for background\n",
    " 5, # Number of iterations\n",
    " cv2.GC_INIT_WITH_RECT) # Initiative using our rectangle\n",
    "# Create mask where sure and likely backgrounds set to 0, otherwise 1\n",
    "mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
    "# Multiply image with new mask to subtract background\n",
    "image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\n",
    "# Show image\n",
    "plt.imshow(image_rgb_nobg), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 Detecting Edges\n",
    "### Problem\n",
    "You want to find the edges in an image.\n",
    "### Solution\n",
    "Use an edge detection technique like the Canny edge detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load library\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image_gray = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Calculate median intensity\n",
    "median_intensity = np.median(image_gray)\n",
    "# Set thresholds to be one standard deviation above and below median intensity\n",
    "lower_threshold = int(max(0, (1.0 - 0.33) * median_intensity))\n",
    "upper_threshold = int(min(255, (1.0 + 0.33) * median_intensity))\n",
    "# Apply canny edge detector\n",
    "image_canny = cv2.Canny(image_gray, lower_threshold, upper_threshold)\n",
    "# Show image\n",
    "plt.imshow(image_canny, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12 Detecting Corners\n",
    "### Problem\n",
    "You want to detect the corners in an image.\n",
    "### Solution\n",
    "Use OpenCV’s implementation of the Harris corner detector, cornerHarris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image_bgr = cv2.imread(\"images/plane_256x256.jpg\")\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "image_gray = np.float32(image_gray)\n",
    "# Set corner detector parameters\n",
    "block_size = 2\n",
    "aperture = 29\n",
    "free_parameter = 0.04\n",
    "# Detect corners\n",
    "detector_responses = cv2.cornerHarris(image_gray,\n",
    "                                      block_size,\n",
    "                                      aperture,\n",
    "                                      free_parameter)\n",
    "# Large corner markers\n",
    "detector_responses = cv2.dilate(detector_responses, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep detector responses greater than threshold, mark as white\n",
    "threshold = 0.02\n",
    "image_bgr[detector_responses >\n",
    "          threshold *\n",
    "          detector_responses.max()] = [255,255,255]\n",
    "# Convert to grayscale\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Show image\n",
    "plt.imshow(image_gray, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show potential corners\n",
    "plt.imshow(detector_responses, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "image_bgr = cv2.imread('download.jfif')\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Number of corners to detect\n",
    "corners_to_detect = 10\n",
    "minimum_quality_score = 0.05\n",
    "minimum_distance = 25\n",
    "# Detect corners\n",
    "corners = cv2.goodFeaturesToTrack(image_gray,\n",
    "                                  corners_to_detect,\n",
    "                                  minimum_quality_score,\n",
    "                                  minimum_distance)\n",
    "corners = np.float32(corners)\n",
    "# Draw white circle at each corner\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    cv2.circle(image_bgr, (x,y), 10, (255,255,255), -1)\n",
    "# Convert to grayscale\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# Show image\n",
    "plt.imshow(image_rgb, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13 Creating Features for Machine Learning\n",
    "### Problem\n",
    "You want to convert an image into an observation for machine learning.\n",
    "### Solution\n",
    "Use NumPy’s flatten to convert the multidimensional array containing an image’s\n",
    "data into a vector containing the observation’s values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as grayscale\n",
    "image = cv2.imread(\"download.jfif\", cv2.IMREAD_GRAYSCALE)\n",
    "# Resize image to 10 pixels by 10 pixels\n",
    "image_10x10 = cv2.resize(image, (10, 10))\n",
    "# Convert image data to one-dimensional vector\n",
    "image_10x10.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14 Encoding Mean Color as a Feature\n",
    "### Problem\n",
    "You want a feature based on the colors of an image.\n",
    "### Solution\n",
    "Each pixel in an image is represented by the combination of multiple color channels\n",
    "(often three: red, green, and blue). Calculate the mean red, green, and blue channel\n",
    "values for an image to make three color features representing the average colors in\n",
    "that image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image as BGR\n",
    "image_bgr = cv2.imread(\"download.jfif\", cv2.IMREAD_COLOR)\n",
    "# Calculate the mean of each channel\n",
    "channels = cv2.mean(image_bgr)\n",
    "# Swap blue and red values (making it RGB, not BGR)\n",
    "observation = np.array([(channels[2], channels[1], channels[0])])\n",
    "# Show mean channel values\n",
    "observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 Encoding Color Histograms as Features\n",
    "### Problem\n",
    "You want to create a set of features representing the colors appearing in an image.\n",
    "### Solution\n",
    "Compute the histograms for each color channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# Load image\n",
    "image_bgr = cv2.imread(\"download.jfif\", cv2.IMREAD_COLOR)\n",
    "# Convert to RGB\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "# Create a list for feature values\n",
    "features = []\n",
    "# Calculate the histogram for each color channel\n",
    "colors = (\"r\",\"g\",\"b\")\n",
    "# For each channel: calculate histogram and add to feature value list\n",
    "for i, channel in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image_rgb], # Image\n",
    "                             [i], # Index of channel\n",
    "                             None, # No mask\n",
    "                             [256], # Histogram size\n",
    "                             [0,256]) # Range\n",
    "    features.extend(histogram)\n",
    "# Create a vector for an observation's feature values\n",
    "observation = np.array(features).flatten()\n",
    "# Show the observation's value for the first five features\n",
    "observation[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = (\"r\",\"g\",\"b\")\n",
    "# For each channel: calculate histogram and add to feature value list\n",
    "for i, channel in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image_rgb], # Image\n",
    "                             [i], # Index of channel\n",
    "                             None, # No mask\n",
    "                             [256], # Histogram size\n",
    "                             [0,256]) # Range\n",
    "    plt.plot(histogram, color = channel)\n",
    "    plt.xlim([0,256])\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearning] *",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
