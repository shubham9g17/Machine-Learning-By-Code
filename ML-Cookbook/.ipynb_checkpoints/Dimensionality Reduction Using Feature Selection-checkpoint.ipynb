{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Thresholding Numerical Feature Variance\n",
    "### Problem\n",
    "You have a set of numerical features and want to remove those with low variance (i.e.,\n",
    "likely containing little information).\n",
    "### Solution\n",
    "Select a subset of features with variances above a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 1.4, 0.2],\n",
       "       [4.9, 1.4, 0.2],\n",
       "       [4.7, 1.3, 0.2]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "# Create features and target\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Create thresholder\n",
    "thresholder = VarianceThreshold(threshold=.5)\n",
    "# Create high variance feature matrix\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "# View high variance feature matrix\n",
    "features_high_variance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68112222, 0.18871289, 3.09550267, 0.57713289])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View variances\n",
    "thresholder.fit(features).variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Finally, if the features have been standardized (to mean zero and unit variance), then\n",
    "for obvious reasons variance thresholding will not work correctly:`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Thresholding Binary Feature Variance\n",
    "### Problem\n",
    "You have a set of binary categorical features and want to remove those with low variance (i.e., likely containing little information).\n",
    "### Solution\n",
    "Select a subset of features with a Bernoulli random variable variance above a given\n",
    "threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "# Create feature matrix with:\n",
    "# Feature 0: 80% class 0\n",
    "# Feature 1: 80% class 1\n",
    "# Feature 2: 60% class 0, 40% class 1\n",
    "features = [[0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [1, 0, 0]]\n",
    "# Run threshold by variance\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Var x = p * 1 − p\n",
    "where p is the proportion of observations of class 1. Therefore, by setting p, we can\n",
    "remove features where the vast majority of observations are one class.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Handling Highly Correlated Features\n",
    "### Problem\n",
    "You have a feature matrix and suspect some features are highly correlated.\n",
    "### Solution\n",
    "Use a correlation matrix to check for highly correlated features. If highly correlated\n",
    "features exist, consider dropping one of the correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  2\n",
       "0  1  1\n",
       "1  2  0\n",
       "2  3  1\n",
       "3  4  0\n",
       "4  5  1\n",
       "5  6  0\n",
       "6  7  1\n",
       "7  8  0\n",
       "8  9  1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Create feature matrix with two highly correlated features\n",
    "features = np.array([[1, 1, 1],\n",
    "                     [2, 2, 0],\n",
    "                     [3, 3, 1],\n",
    "                     [4, 4, 0],\n",
    "                     [5, 5, 1],\n",
    "                     [6, 6, 0],\n",
    "                     [7, 7, 1],\n",
    "                     [8, 7, 0],\n",
    "                     [9, 7, 1]])\n",
    "# Convert feature matrix into DataFrame\n",
    "dataframe = pd.DataFrame(features)\n",
    "# Create correlation matrix\n",
    "corr_matrix = dataframe.corr().abs()\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape),\n",
    "                                  k=1).astype(np.bool))\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "# Drop features\n",
    "dataframe.drop(dataframe.columns[to_drop], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Removing Irrelevant Features for Classification\n",
    "### Problem\n",
    "You have a categorical target vector and want to remove uninformative features.\n",
    "### Solution\n",
    "If the features are categorical, calculate a chi-square (χ2\n",
    ") statistic between each feature\n",
    "and the target vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "# Convert to categorical data by converting data to integers\n",
    "features = features.astype(int)\n",
    "# Select two features with highest chi-squared statistics\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "# Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`If the features are quantitative, compute the ANOVA F-value between each feature\n",
    "and the target vector:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 2\n"
     ]
    }
   ],
   "source": [
    "# Select two features with highest F-values\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "# Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 4\n",
      "Reduced number of features: 3\n"
     ]
    }
   ],
   "source": [
    "# Load library\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "# Select top 75% of features with highest F-values\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "# Show results\n",
    "print(\"Original number of features:\", features.shape[1])\n",
    "print(\"Reduced number of features:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Recursively Eliminating Features\n",
    "### Problem\n",
    "You want to automatically select the best features to keep.\n",
    "### Solution\n",
    "Use scikit-learn’s RFECV to conduct recursive feature elimination (RFE) using crossvalidation (CV). That is, repeatedly train a model, each time removing a feature until\n",
    "model performance (e.g., accuracy) becomes worse. The remaining features are the\n",
    "best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00850799, -0.28547464,  0.7031277 ],\n",
       "       [-1.07500204, -0.8689623 ,  2.56148527],\n",
       "       [ 1.37940721, -0.14714771, -1.77039484],\n",
       "       ...,\n",
       "       [-0.80331656, -1.030216  , -1.60648007],\n",
       "       [ 0.39508844, -0.91553464, -1.34564911],\n",
       "       [-0.55383035, -0.69804472,  0.82880112]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load libraries\n",
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "# Suppress an annoying but harmless warning\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\",\n",
    " message=\"^internal gelsd\")\n",
    "# Generate features matrix, target vector, and the true coefficients\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features = 100,\n",
    "                                   n_informative = 2,\n",
    "                                   random_state = 1)\n",
    "# Create a linear regression\n",
    "ols = linear_model.LinearRegression()\n",
    "# Recursively eliminate features\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of best features\n",
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80, 98, 39, 86, 31,  1,  8, 74, 58, 33, 30, 32,  4, 20, 13, 71, 24,\n",
       "       12, 96, 60, 62, 26, 23,  9, 36, 82, 19, 84, 10, 21, 17, 61,  1, 73,\n",
       "       16, 14, 65, 63, 11,  1, 40, 92, 37, 91, 94, 85, 29, 15, 67, 57, 66,\n",
       "       56, 83, 18, 46, 38, 41, 45, 54, 68, 89, 59, 81, 75, 42, 78, 88, 22,\n",
       "       25,  2, 44, 34,  6, 48, 50,  5, 72, 93, 77, 43, 76, 27,  7, 64, 69,\n",
       "       70,  3, 97, 87, 90, 47, 53, 95, 49, 28, 55, 52, 51, 35, 79])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rank features best (1) to worst\n",
    "rfecv.ranking_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
